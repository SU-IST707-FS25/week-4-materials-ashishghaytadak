# Assignment Feedback: Week 04 Dimensionality Reduction

**Student:** ashishghaytadak
**Raw Score:** 49/50 (98.0%)
**Course Points Earned:** 100.0

---

## Problem Breakdown

### Exercise 2 (10/10 = 100.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Well done. You correctly applied t-SNE on a subset of MNIST, projected to 2D, and visualized with labels and a colorbar. Using a subset for speed is appropriate, and parameters are sensible. Plot is clear and meets the exercise goal.

**Part ex1-part2** (ex1-part2.code): 3/3 points

_Feedback:_ Good job: you trained KNN on your t-SNE features, did a train/test split, and reported accuracy. This directly answers the prompt using your prior t-SNE. For improvement, briefly interpret the accuracy (e.g., compare to raw features) or tune k.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Full credit. You correctly split the UMAP embeddings, trained a KNN, predicted on the test split, and computed accuracy. Variables align with prior UMAP work. Nice job.

---

### Exercise 4 (19/20 = 95.0%)

**Part ex2-part1** (ex2-part1.code): 7/7 points

_Feedback:_ Good job applying PCA with multiple component counts and evaluating KNN accuracy. This meets the goal effectively. For further insight, you could also try variance-based PCA (e.g., PCA(0.9)) or visualize the first two PCs, but your approach is correct and sufficient.

**Part ex2-part2** (ex2-part2.code): 7/7 points

_Feedback:_ Excellent. You correctly swapped PCA for UMAP, fit on X_train, transformed X_test, and evaluated KNN across 1–3 components. Clear, working implementation aligned with your prior approach. For exploration, a 2D scatter plot could be added, but not required.

**Part ex2-part3** (ex2-part3.answer): 5/6 points

_Feedback:_ Good comparison and parameter exploration (1–3 dims) using your prior PCA/UMAP runs. You correctly note UMAP’s strength for nonlinear structure. To earn full credit, mention that UMAP often works best in low dims (e.g., 2D) with low n_neighbors; you didn’t address that.

---

### Exercise 1 (20/20 = 100.0%)

**Part pipeline-part1** (pipeline-part1.code): 4/4 points

_Feedback:_ Well done. You correctly applied PCA to 2 components and produced a clear 2D scatter plot colored by digit class with labels and colorbar. This fully meets the task requirements.

**Part pipeline-part2** (pipeline-part2.code): 4/4 points

_Feedback:_ Excellent. You fit PCA with 40 components, computed percent variance explained, and plotted the first 40 components. The y-axis correctly reflects percent variance. Meets the scree plot requirements.

**Part pipeline-part3** (pipeline-part3.code): 4/4 points

_Feedback:_ Correctly fits PCA on full training set, computes cumulative explained variance, and finds components to reach 95%. This meets the objective and should work with prior data. Extra digit-plotting cell is fine but unrelated. Well done.

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Excellent. You correctly used n_components_95 from Step 4, reduced then reconstructed the digit, and plotted it with the provided function. Using inverse_transform is the right approach to visualize in pixel space. Nicely done.

**Part pipeline-part5** (pipeline-part5.code): 4/4 points

_Feedback:_ Well done. You correctly trained KNN on original data and after PCA, preserving ~80% variance with PCA(n_components=0.80). You transformed both train and test sets and compared accuracies. Implementation aligns with prior work and task requirements.

---

## Additional Information

This feedback was automatically generated by the autograder.

**Generated:** 2025-10-28 19:51:32 UTC

If you have questions about your grade, please reach out to the instructor.