# Assignment Feedback: Week 4: Dimensionality Reduction

**Student:** ashishghaytadak
**Total Score:** 25/40 (62.5%)

**Grade Category:** D (Poor)

---

## Problem Breakdown

### Exercise 1 (6/16 = 37.5%)

**Part pipeline-part1** (pipeline-part1.code): 0/0 points

_Feedback:_ Good job: you applied PCA to 2D and produced a clear scatter plot colored by digit—meets the reduction and visualization goal. For enhancement, consider showing explained variance and/or image reconstructions to illustrate approximation quality.

**Part pipeline-part2** (pipeline-part2.code): 1/4 points

_Feedback:_ You performed PCA and produced a valid scree plot, but the task required reducing to 2 components and visualizing a 2D scatter colored by class. Your code uses 40 components and no class-colored scatter. For full credit: PCA(n_components=2) and scatter with c=y_mnist_train.

**Part pipeline-part3** (pipeline-part3.code): 1/4 points

_Feedback:_ You did PCA and computed cumulative variance, but you didn’t produce the required scree plot of the first 40 components with percent variance explained on the y-axis. The second cell (digit plot) is unrelated. Plot the first 40 PCs’ variance (%) to earn full credit.

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Good job. You correctly used the previously computed n_components_95 to select PCA components explaining 95% variance, fit-transform the data, and even demonstrated reconstruction. This satisfies the step’s goal of selecting the number of components.

**Part pipeline-part5** (pipeline-part5.code): 0/4 points

_Feedback:_ This doesn’t address Step 5. You implemented KNN before/after PCA (80% variance) but did not visualize a digit from the reduced space. Use your n_components_95 PCA, transform a digit, inverse_transform it, and plot with plot_mnist_digit. No import penalties applied.

---

### Exercise 2 (10/10 = 100.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Correct and complete t-SNE visualization. Using a subset for speed is appropriate. Parameters are reasonable, plot is well-labeled and colored by class with a colorbar. Optionally, you could tune perplexity or try more samples if compute allows.

**Part ex1-part2** (ex1-part2.code): 3/3 points

_Feedback:_ Good job: you split the t-SNE embedding, fit KNN, and reported accuracy. This directly answers the prompt. For completeness, add a brief comment interpreting whether the accuracy is strong/weak vs. baseline or raw-pixel KNN.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Good job. You split the UMAP embedding into train/test, fit KNN, and computed accuracy correctly, consistent with prior work. This meets the objective of calculating accuracy with KNN. No issues detected.

---

### Exercise 4 (9/14 = 64.3%)

**Part ex2-part1** (ex2-part1.code): 0/0 points

_Feedback:_ Good start: you evaluate KNN accuracy after PCA with 1–3 components using the train/test split. However, you didn’t explore UMAP or its parameters, nor visualize embeddings. Add UMAP (vary n_components, n_neighbors, min_dist) and plots to compare trends.

**Part ex2-part2** (ex2-part2.code): 3/7 points

_Feedback:_ You implemented dimensionality reduction + KNN correctly, but you used UMAP instead of PCA as requested and as in your prior work. Replace UMAP with PCA to meet the exercise goal. Looping over n_components and reporting accuracy is good; no need to penalize imports.

**Part ex2-part3** (ex2-part3.answer): 6/7 points

_Feedback:_ Good conceptual comparison and reasonable interpretation (UMAP > PCA for nonlinear data; accuracy improving with more components). To strengthen, report the actual accuracies from your run and briefly tie claims to those results. Otherwise solid understanding.

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-10-27 18:51:09 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*